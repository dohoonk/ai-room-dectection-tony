{
  "master": {
    "tasks": [
      {
        "id": 1,
        "title": "Set Up Development Environment",
        "description": "Initialize the development environment with necessary tools, libraries, and testing frameworks.",
        "status": "done",
        "dependencies": [],
        "priority": "medium",
        "details": "Install Node.js, Python, and necessary libraries such as React, Material UI, Express.js, FastAPI, networkx, and shapely. Set up a version control system using Git. Additionally, install and configure pytest for Python backend testing and Jest with React Testing Library for React frontend testing. Set up test configuration files for both frameworks.",
        "testStrategy": "Verify installation by running a simple React app and a Python script. Ensure pytest and Jest are properly configured by running sample tests for both the backend and frontend.",
        "subtasks": [
          {
            "id": 1,
            "title": "Install Node.js and Python",
            "description": "Install the latest versions of Node.js and Python.",
            "dependencies": [],
            "details": "Use package managers like nvm for Node.js and pyenv for Python.",
            "status": "done",
            "testStrategy": "Run 'node -v' and 'python --version' to verify installations."
          },
          {
            "id": 2,
            "title": "Set Up Version Control",
            "description": "Initialize a Git repository for the project.",
            "dependencies": [],
            "details": "Create a new repository on GitHub and clone it locally.",
            "status": "done",
            "testStrategy": "Verify by committing a README file."
          },
          {
            "id": 3,
            "title": "Install Frontend Libraries",
            "description": "Install React and Material UI.",
            "dependencies": [],
            "details": "Use npm to install React and Material UI.",
            "status": "done",
            "testStrategy": "Create a simple React component to verify installation."
          },
          {
            "id": 4,
            "title": "Install Backend Libraries",
            "description": "Install Express.js, FastAPI, networkx, and shapely.",
            "dependencies": [],
            "details": "Use npm for Express.js and pip for Python libraries.",
            "status": "done",
            "testStrategy": "Run a basic Express server and a Python script using FastAPI."
          },
          {
            "id": 5,
            "title": "Set Up Testing Frameworks",
            "description": "Install and configure pytest and Jest with React Testing Library.",
            "dependencies": [],
            "details": "Use pip to install pytest and npm for Jest and React Testing Library. Create configuration files for both frameworks.",
            "status": "done",
            "testStrategy": "Run sample tests to ensure both frameworks are correctly configured."
          }
        ]
      },
      {
        "id": 2,
        "title": "Create Sample Test Data",
        "description": "Develop sample blueprint images and wall-line JSON files for testing.",
        "details": "Create a set of JSON files representing wall line segments and corresponding PNG/JPG images for visual reference. Ensure data covers various room configurations.",
        "testStrategy": "Manually verify that JSON data accurately represents the visual blueprint images.",
        "priority": "medium",
        "dependencies": [
          1
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Create Simple Floorplan JSON",
            "description": "Develop a JSON file for a simple room configuration.",
            "dependencies": [],
            "details": "Design a JSON structure to represent basic wall line segments for a simple room. Ensure the format is consistent with project standards.",
            "status": "done",
            "testStrategy": "Verify JSON structure against a predefined schema."
          },
          {
            "id": 2,
            "title": "Create Complex Floorplan JSON",
            "description": "Develop a JSON file for a complex room configuration.",
            "dependencies": [
              1
            ],
            "details": "Design a JSON structure to represent complex wall line segments, including multiple rooms and corridors. Ensure the format is consistent with project standards.",
            "status": "done",
            "testStrategy": "Verify JSON structure against a predefined schema and test with edge cases."
          },
          {
            "id": 3,
            "title": "Generate Corresponding Blueprint Images",
            "description": "Create PNG/JPG images for the JSON floorplans.",
            "dependencies": [
              1,
              2
            ],
            "details": "Use graphic design tools to create visual representations of the simple and complex floorplans. Ensure images match the JSON data accurately.",
            "status": "done",
            "testStrategy": "Manually compare images with JSON data to ensure accuracy."
          },
          {
            "id": 4,
            "title": "Organize Test Data Structure",
            "description": "Organize JSON files and images into a structured directory.",
            "dependencies": [
              3
            ],
            "details": "Create a directory structure to store JSON files and images. Ensure easy access and retrieval for testing purposes.",
            "status": "done",
            "testStrategy": "Verify that all files are correctly named and stored in the appropriate directories."
          },
          {
            "id": 5,
            "title": "Document Test Cases for Sample Data",
            "description": "Write documentation for testing the sample data.",
            "dependencies": [
              4
            ],
            "details": "Create a document outlining test cases for verifying the accuracy of JSON and image data. Include steps for manual verification and expected outcomes.",
            "status": "done",
            "testStrategy": "Review documentation for completeness and clarity."
          }
        ]
      },
      {
        "id": 3,
        "title": "Implement Core Algorithm: Parse Line Segments",
        "description": "Develop functionality to parse line segments from JSON input.",
        "status": "done",
        "dependencies": [
          1
        ],
        "priority": "medium",
        "details": "Use Python to read JSON input and extract line segment data. Ensure data is structured for further processing. Implement robust error handling for invalid JSON and edge cases.",
        "testStrategy": "Create pytest unit tests to cover valid JSON parsing, invalid JSON handling, edge cases (empty arrays, malformed data), and verify correct data structure output. Include at least 5-7 test cases to ensure comprehensive coverage of the parsing logic.",
        "subtasks": [
          {
            "id": 1,
            "title": "Write unit test for valid JSON parsing",
            "description": "Ensure that valid JSON input is correctly parsed into line segment data structures.",
            "dependencies": [],
            "details": "Use pytest to write a test case that checks the parsing of a well-formed JSON input.",
            "status": "done",
            "testStrategy": "Verify that the parsed output matches the expected data structure."
          },
          {
            "id": 2,
            "title": "Write unit test for invalid JSON handling",
            "description": "Test the parser's response to invalid JSON input.",
            "dependencies": [],
            "details": "Use pytest to write a test case that checks how the parser handles malformed JSON.",
            "status": "done",
            "testStrategy": "Ensure that appropriate exceptions are raised for invalid JSON."
          },
          {
            "id": 3,
            "title": "Write unit test for edge cases",
            "description": "Test the parser with edge cases such as empty arrays and malformed data.",
            "dependencies": [],
            "details": "Use pytest to write test cases for edge scenarios.",
            "status": "done",
            "testStrategy": "Verify that the parser handles edge cases gracefully without crashing."
          },
          {
            "id": 4,
            "title": "Verify correct data structure output",
            "description": "Ensure that the parsed data is structured correctly for further processing.",
            "dependencies": [],
            "details": "Use pytest to write test cases that validate the structure of the parsed data.",
            "status": "done",
            "testStrategy": "Check that the output data structure matches the expected format."
          },
          {
            "id": 5,
            "title": "Create Python Module Structure",
            "description": "Set up the Python module structure for the line segment parser",
            "details": "Create a new Python module file (e.g., `parser.py`) with proper structure and imports. Set up the basic function skeleton for parsing line segments.",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 3
          },
          {
            "id": 6,
            "title": "Implement JSON Parsing Function",
            "description": "Implement the core function to parse JSON and extract line segment data",
            "details": "Write a function that reads JSON input, validates the structure, and extracts line segment data (start, end coordinates, type, is_load_bearing).",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 3
          },
          {
            "id": 7,
            "title": "Implement Data Validation",
            "description": "Add validation for line segment data structure",
            "details": "Validate that each line segment has required fields (type, start, end) and that coordinates are valid numbers within expected ranges.",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 3
          },
          {
            "id": 8,
            "title": "Implement Error Handling",
            "description": "Add robust error handling for invalid JSON and edge cases",
            "details": "Handle cases like malformed JSON, missing fields, invalid data types, and empty arrays. Return meaningful error messages.",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 3
          }
        ]
      },
      {
        "id": 4,
        "title": "Implement Core Algorithm: Snap Endpoints",
        "description": "Snap endpoints within a tolerance to form a wall adjacency graph.",
        "status": "done",
        "dependencies": [
          3
        ],
        "priority": "medium",
        "details": "Utilize networkx to create a graph from line segments, snapping endpoints within a specified tolerance to connect walls. Implement pytest unit tests to ensure comprehensive coverage.",
        "testStrategy": "Create pytest unit tests covering: endpoint snapping with various tolerance levels, graph construction correctness, edge cases (overlapping endpoints, isolated segments), and verify graph structure. Include at least 5-7 test cases for good coverage.",
        "subtasks": [
          {
            "id": 1,
            "title": "Develop Unit Tests for Endpoint Snapping",
            "description": "Create pytest unit tests for snapping endpoints with various tolerance levels.",
            "dependencies": [],
            "details": "Ensure tests cover different tolerance values to verify snapping accuracy.",
            "status": "done",
            "testStrategy": "Use pytest to validate endpoint snapping across multiple tolerance settings."
          },
          {
            "id": 2,
            "title": "Test Graph Construction Correctness",
            "description": "Develop tests to ensure the graph is constructed correctly from snapped endpoints.",
            "dependencies": [],
            "details": "Verify that the graph accurately represents the adjacency of walls.",
            "status": "done",
            "testStrategy": "Check graph structure and connections using pytest."
          },
          {
            "id": 3,
            "title": "Handle Edge Cases in Graph Construction",
            "description": "Create tests for edge cases such as overlapping endpoints and isolated segments.",
            "dependencies": [],
            "details": "Ensure edge cases are handled correctly in the graph construction process.",
            "status": "done",
            "testStrategy": "Use pytest to test edge cases and verify graph integrity."
          },
          {
            "id": 4,
            "title": "Verify Overall Graph Structure",
            "description": "Ensure the final graph structure is as expected with all connections intact.",
            "dependencies": [],
            "details": "Check the overall integrity and correctness of the graph structure.",
            "status": "done",
            "testStrategy": "Conduct comprehensive tests to validate the final graph structure."
          },
          {
            "id": 5,
            "title": "Implement Endpoint Snapping Algorithm",
            "description": "Create the algorithm to snap endpoints within tolerance",
            "details": "Implement logic to find endpoints that are within a specified tolerance distance and group them together for graph construction.",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 4
          },
          {
            "id": 6,
            "title": "Create NetworkX Graph Structure",
            "description": "Build the graph using networkx from snapped endpoints",
            "details": "Use networkx to create a graph where nodes represent endpoints and edges represent wall segments. Connect nodes based on snapped endpoint groups.",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 4
          },
          {
            "id": 7,
            "title": "Implement Tolerance-Based Connection Logic",
            "description": "Implement the logic to connect walls based on tolerance",
            "details": "Create a function that determines which wall endpoints should be connected based on distance tolerance, ensuring walls are properly linked in the graph.",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 4
          },
          {
            "id": 8,
            "title": "Integrate with Parsed Line Segments",
            "description": "Connect the snapping algorithm with the parser from task 3",
            "details": "Ensure the endpoint snapping function accepts the parsed line segment data structure and processes it correctly.",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 4
          }
        ]
      },
      {
        "id": 5,
        "title": "Implement Core Algorithm: Detect Closed Loops",
        "description": "Detect closed loops (cycles) in the wall adjacency graph.",
        "status": "done",
        "dependencies": [
          4
        ],
        "priority": "medium",
        "details": "Use networkx to identify cycles in the graph, representing potential room boundaries. Implement pytest unit tests to ensure comprehensive coverage of cycle detection.",
        "testStrategy": "Create pytest unit tests covering: cycle detection in simple and complex graphs, handling of graphs with no cycles, multiple cycles, nested cycles, and verify all closed loops are identified. Include at least 5-7 test cases with good coverage.",
        "subtasks": [
          {
            "id": 1,
            "title": "Develop Unit Tests for Cycle Detection",
            "description": "Create pytest unit tests for cycle detection in various graph scenarios.",
            "dependencies": [],
            "details": "Develop tests for simple graphs, complex graphs, graphs with no cycles, multiple cycles, and nested cycles.",
            "status": "done",
            "testStrategy": "Ensure all test cases are executed and validate the correct identification of closed loops."
          },
          {
            "id": 2,
            "title": "Implement Cycle Detection Algorithm",
            "description": "Use networkx to detect cycles in the graph",
            "details": "Implement a function that uses networkx cycle detection algorithms to find all closed loops in the wall adjacency graph.\n<info added on 2025-11-08T21:33:09.616Z>\n✅ COMPLETED: Implemented comprehensive face-finding algorithm for multi-room detection.\n\nImplementation details:\n- Created `split_lines_at_intersections()` function to split wall segments at all intersection points\n- Implemented `find_faces_using_polygonize()` using Shapely's polygonize to find all bounded regions\n- Added `find_faces_in_planar_graph()` as fallback using networkx graph-based cycle detection\n- Algorithm successfully detects:\n  * Simple floorplans: 1 room ✓\n  * Multi-room floorplans: 3-4 rooms ✓\n  * Complex floorplans with internal walls: All bounded regions ✓\n\nThe face-finding algorithm properly handles T-junctions and internal walls, enabling full multi-room detection as required for MVP.\n</info added on 2025-11-08T21:33:09.616Z>",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 5
          },
          {
            "id": 3,
            "title": "Filter Duplicate Cycles",
            "description": "Remove duplicate and redundant cycles",
            "details": "Implement logic to filter out duplicate cycles (same nodes in different order) and ensure each unique cycle is only returned once.",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 5
          },
          {
            "id": 4,
            "title": "Structure Cycle Data for Processing",
            "description": "Format detected cycles for further processing",
            "details": "Convert networkx cycle data into a structured format (list of node sequences) that can be used by subsequent algorithm steps.",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 5
          }
        ]
      },
      {
        "id": 6,
        "title": "Implement Core Algorithm: Filter Cycles",
        "description": "Filter detected cycles by size and shape to ignore invalid polygons.",
        "status": "done",
        "dependencies": [
          5
        ],
        "priority": "medium",
        "details": "Apply filtering criteria to remove small or irregular cycles that do not represent valid rooms. Implement pytest unit tests to ensure the filtering criteria are correctly applied.",
        "testStrategy": "Create pytest unit tests covering: filtering small cycles, filtering irregular shapes, keeping valid room-sized cycles, and edge cases (boundary conditions). Include at least 5-7 test cases for comprehensive coverage.",
        "subtasks": [
          {
            "id": 1,
            "title": "Create pytest unit tests for filtering small cycles",
            "description": "Develop unit tests to ensure small cycles are filtered out correctly.",
            "dependencies": [],
            "details": "Write tests that check if cycles below a certain size threshold are removed.",
            "status": "done",
            "testStrategy": "Verify small cycles are consistently filtered out across different configurations."
          },
          {
            "id": 2,
            "title": "Create pytest unit tests for filtering irregular shapes",
            "description": "Develop unit tests to ensure irregular shapes are filtered out correctly.",
            "dependencies": [],
            "details": "Write tests that check if cycles with irregular shapes are removed.",
            "status": "done",
            "testStrategy": "Verify irregular shapes are consistently filtered out across different configurations."
          },
          {
            "id": 3,
            "title": "Create pytest unit tests for keeping valid room-sized cycles",
            "description": "Develop unit tests to ensure valid room-sized cycles are retained.",
            "dependencies": [],
            "details": "Write tests that check if cycles representing valid rooms are kept.",
            "status": "done",
            "testStrategy": "Verify valid room-sized cycles are consistently retained across different configurations."
          },
          {
            "id": 4,
            "title": "Create pytest unit tests for edge cases",
            "description": "Develop unit tests to cover edge cases in filtering criteria.",
            "dependencies": [],
            "details": "Write tests for boundary conditions and unusual scenarios.",
            "status": "done",
            "testStrategy": "Ensure edge cases are handled correctly without false positives or negatives."
          },
          {
            "id": 5,
            "title": "Verify filtering criteria with comprehensive test coverage",
            "description": "Ensure the filtering criteria work correctly with a variety of test cases.",
            "dependencies": [],
            "details": "Review and refine test cases to ensure all aspects of filtering are covered.",
            "status": "done",
            "testStrategy": "Ensure all test cases pass and provide good coverage of the filtering logic."
          },
          {
            "id": 6,
            "title": "Implement Size-Based Filtering",
            "description": "Filter cycles based on size thresholds",
            "details": "Implement logic to calculate cycle area/perimeter and filter out cycles that are too small to represent valid rooms (e.g., closets, hall fragments).",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 6
          },
          {
            "id": 7,
            "title": "Implement Shape-Based Filtering",
            "description": "Filter cycles based on shape characteristics",
            "details": "Implement logic to identify and filter out irregular shapes (e.g., extremely elongated, non-convex) that don't represent typical rooms.",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 6
          },
          {
            "id": 8,
            "title": "Define Filtering Criteria and Thresholds",
            "description": "Establish the filtering parameters",
            "details": "Define minimum size thresholds, aspect ratio limits, and other criteria for determining valid room cycles. Make these configurable.",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 6
          },
          {
            "id": 9,
            "title": "Apply Filters to Detected Cycles",
            "description": "Apply all filtering criteria to the cycle list",
            "details": "Create a function that applies size and shape filters to the list of detected cycles, returning only valid room candidates.",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 6
          }
        ]
      },
      {
        "id": 7,
        "title": "Implement Core Algorithm: Convert Polygon to Bounding Box",
        "description": "Convert detected polygons into axis-aligned bounding boxes.",
        "status": "done",
        "dependencies": [
          6
        ],
        "priority": "medium",
        "details": "Use shapely to convert polygon cycles into bounding boxes, ensuring they are axis-aligned for simplicity. Implement pytest unit tests to cover bounding box calculation accuracy, axis-aligned conversion, and edge cases such as degenerate polygons and single points.",
        "testStrategy": "Create pytest unit tests to verify bounding boxes accurately encompass the detected polygons. Include at least 5-7 test cases to ensure good coverage, focusing on accuracy, axis alignment, and handling of edge cases.",
        "subtasks": [
          {
            "id": 1,
            "title": "Develop Unit Tests for Bounding Box Calculation",
            "description": "Create pytest unit tests to verify the accuracy of bounding box calculations.",
            "dependencies": [],
            "details": "Ensure tests cover various polygon shapes and sizes.",
            "status": "done",
            "testStrategy": "Use pytest to validate bounding box dimensions against expected results."
          },
          {
            "id": 2,
            "title": "Test Axis-Aligned Conversion",
            "description": "Ensure bounding boxes are axis-aligned.",
            "dependencies": [],
            "details": "Test with polygons that have non-axis-aligned edges to confirm conversion.",
            "status": "done",
            "testStrategy": "Verify that all bounding boxes are axis-aligned post-conversion."
          },
          {
            "id": 3,
            "title": "Handle Edge Cases",
            "description": "Test edge cases such as degenerate polygons and single points.",
            "dependencies": [],
            "details": "Include tests for polygons that collapse into lines or points.",
            "status": "done",
            "testStrategy": "Ensure bounding boxes are correctly calculated for edge cases."
          },
          {
            "id": 4,
            "title": "Verify Encompassment of Polygons",
            "description": "Ensure bounding boxes correctly encompass the original polygons.",
            "dependencies": [],
            "details": "Test with complex polygons to ensure full coverage.",
            "status": "done",
            "testStrategy": "Check that bounding boxes fully contain the polygons without excess space."
          },
          {
            "id": 5,
            "title": "Implement Polygon to Bounding Box Conversion",
            "description": "Use shapely to convert cycles to bounding boxes",
            "details": "Implement a function that takes a cycle (list of nodes) and uses shapely to create a polygon, then extract its axis-aligned bounding box.",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 7
          },
          {
            "id": 6,
            "title": "Ensure Axis-Alignment",
            "description": "Verify bounding boxes are axis-aligned",
            "details": "Ensure all bounding boxes are axis-aligned (aligned with x and y axes) as required by the MVP specification.",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 7
          },
          {
            "id": 7,
            "title": "Calculate Bounding Box Coordinates",
            "description": "Extract min/max coordinates for each bounding box",
            "details": "Calculate and return the bounding box coordinates in the format [min_x, min_y, max_x, max_y] for each detected room.",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 7
          }
        ]
      },
      {
        "id": 8,
        "title": "Normalize Bounding Box Coordinates",
        "description": "Normalize bounding box coordinates to a 0–1000 scale.",
        "status": "done",
        "dependencies": [
          7
        ],
        "priority": "medium",
        "details": "Scale bounding box coordinates to fit within a 0–1000 coordinate system, maintaining aspect ratio. Implement pytest unit tests to ensure correctness.",
        "testStrategy": "Create pytest unit tests to cover normalization to 0-1000 range, aspect ratio preservation, edge cases (already normalized, extreme coordinates), and verify all coordinates are within bounds. Include at least 5-7 test cases with good coverage.",
        "subtasks": [
          {
            "id": 1,
            "title": "Develop Unit Tests for Normalization",
            "description": "Create pytest unit tests for bounding box normalization.",
            "dependencies": [],
            "details": "Develop tests to ensure bounding boxes are normalized to a 0-1000 range, maintaining aspect ratio.",
            "status": "done",
            "testStrategy": "Verify that bounding boxes are correctly normalized across various test cases, including edge cases."
          },
          {
            "id": 2,
            "title": "Test Aspect Ratio Preservation",
            "description": "Ensure aspect ratio is preserved during normalization.",
            "dependencies": [
              1
            ],
            "details": "Write tests to confirm aspect ratio is maintained after normalization.",
            "status": "done",
            "testStrategy": "Check aspect ratio consistency across different bounding box dimensions."
          },
          {
            "id": 3,
            "title": "Handle Edge Cases",
            "description": "Test edge cases for bounding box normalization.",
            "dependencies": [
              1
            ],
            "details": "Include tests for already normalized boxes and extreme coordinates.",
            "status": "done",
            "testStrategy": "Ensure edge cases are handled correctly, with coordinates remaining within bounds."
          },
          {
            "id": 4,
            "title": "Implement Normalization Algorithm",
            "description": "Create the normalization function to scale coordinates",
            "details": "Implement a function that scales bounding box coordinates to fit within the 0-1000 coordinate system while maintaining the original aspect ratio.",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 8
          },
          {
            "id": 5,
            "title": "Preserve Aspect Ratio During Scaling",
            "description": "Ensure aspect ratio is maintained during normalization",
            "details": "Calculate the scaling factor that maintains the original aspect ratio while fitting coordinates within the 0-1000 range.",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 8
          },
          {
            "id": 6,
            "title": "Ensure Coordinates Within 0-1000 Range",
            "description": "Validate all coordinates are within bounds",
            "details": "Add validation to ensure all normalized coordinates fall within the 0-1000 range, handling edge cases like already-normalized or extreme coordinates.",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 8
          }
        ]
      },
      {
        "id": 9,
        "title": "Develop Local Backend API",
        "description": "Create a REST API endpoint for room detection using Express.js or FastAPI. This API will work in conjunction with the UI component in task 11 to display detected room bounding boxes.",
        "status": "done",
        "dependencies": [
          3,
          8
        ],
        "priority": "medium",
        "details": "Set up a local server with an endpoint that accepts wall-line JSON and returns detected room bounding boxes. This API will enable manual testing through the React UI developed in task 11. Implement integration tests to ensure the API handles various scenarios effectively.",
        "testStrategy": "Use Postman to test API endpoint, ensuring correct input/output handling. Additionally, verify integration with the React UI in task 11 for manual testing. Create integration tests using pytest (for FastAPI) or Jest/Supertest (for Express) to cover: valid JSON acceptance, correct room detection results, invalid input handling, error handling, and response format validation. Include 5-7 integration test cases for comprehensive coverage.",
        "subtasks": [
          {
            "id": 1,
            "title": "Set Up API Endpoint",
            "description": "Develop the API endpoint using Express.js or FastAPI to handle room detection requests.",
            "dependencies": [],
            "details": "Ensure the endpoint accepts wall-line JSON and returns room bounding boxes.",
            "status": "done",
            "testStrategy": "Use Postman to verify endpoint functionality."
          },
          {
            "id": 2,
            "title": "Create Integration Tests",
            "description": "Develop integration tests for the API endpoint.",
            "dependencies": [],
            "details": "Use pytest for FastAPI or Jest/Supertest for Express to create tests covering valid JSON acceptance, correct room detection results, invalid input handling, error handling, and response format validation.",
            "status": "done",
            "testStrategy": "Ensure tests cover all specified scenarios with 5-7 test cases."
          }
        ]
      },
      {
        "id": 10,
        "title": "Build React Frontend with Material UI",
        "description": "Set up the React project with Material UI and create a basic UI component to visualize wall line segments from JSON.",
        "status": "done",
        "dependencies": [
          1
        ],
        "priority": "medium",
        "details": "Initialize a React project and integrate Material UI. Implement a basic file upload feature for JSON files and create a canvas or SVG component to draw wall line segments based on the JSON data. Include component tests using Jest and React Testing Library for each part.",
        "testStrategy": "Perform manual testing to ensure the React project initializes correctly, Material UI components are styled properly, and the canvas/SVG component accurately visualizes wall line segments from uploaded JSON files. Additionally, implement Jest and React Testing Library tests for each component to ensure functionality and integration.",
        "subtasks": [
          {
            "id": 1,
            "title": "Initialize React Project with Material UI",
            "description": "Set up a new React project and integrate Material UI for styling.",
            "dependencies": [],
            "details": "Use Create React App to initialize the project and add Material UI dependencies.",
            "status": "done",
            "testStrategy": "Ensure the project runs without errors and Material UI components render correctly. Implement Jest and React Testing Library tests to verify Material UI integration."
          },
          {
            "id": 2,
            "title": "Implement JSON File Upload",
            "description": "Create a component to allow users to upload JSON files containing wall line data.",
            "dependencies": [],
            "details": "Develop a file input component that accepts JSON files and reads their content.",
            "status": "done",
            "testStrategy": "Test file upload functionality with sample JSON files to ensure data is read correctly. Include Jest and React Testing Library tests with at least 3-5 test cases to verify component rendering and file handling."
          },
          {
            "id": 3,
            "title": "Create Canvas/SVG Component for Visualization",
            "description": "Develop a component to draw wall line segments on a canvas or SVG based on JSON input.",
            "dependencies": [],
            "details": "Use HTML5 Canvas or SVG to render lines representing wall segments from the JSON data.",
            "status": "done",
            "testStrategy": "Verify that the visual representation matches the data in the JSON files. Implement Jest and React Testing Library tests with at least 3-5 test cases to ensure accurate rendering of wall lines."
          }
        ]
      },
      {
        "id": 11,
        "title": "Integrate Frontend with Backend API",
        "description": "Create the UI component to display detected room bounding boxes using the React frontend, integrating with the local backend API for room detection. Additionally, implement comprehensive component tests using Jest and React Testing Library.",
        "status": "done",
        "dependencies": [
          9,
          10
        ],
        "priority": "medium",
        "details": "Use Material UI components to overlay bounding boxes on the blueprint image, display room IDs, and allow basic interaction. This will serve as the main testing interface for the room detection algorithm. Ensure that the UI is robust and handles various user interactions and API responses effectively.",
        "testStrategy": "Test the UI by uploading test data, verifying that bounding boxes are correctly displayed and interactive, and ensuring room IDs are shown accurately. Implement component tests to cover bounding box overlay rendering, room ID display, user interactions (clicking rooms), API integration, error handling, and Material UI component behavior. Include at least 5-7 test cases for comprehensive coverage.",
        "subtasks": [
          {
            "id": 1,
            "title": "Create Component Tests",
            "description": "Develop component tests using Jest and React Testing Library.",
            "dependencies": [],
            "details": "Write tests to cover bounding box overlay rendering, room ID display, user interactions (clicking rooms), API integration, error handling, and Material UI component behavior. Ensure at least 5-7 test cases are implemented.",
            "status": "done",
            "testStrategy": "Verify that all test cases pass and cover the specified scenarios effectively."
          },
          {
            "id": 2,
            "title": "Create Bounding Box Overlay Component",
            "description": "Build React component to overlay bounding boxes on blueprint",
            "details": "Create a React component that renders bounding boxes as overlays on top of the blueprint image using Material UI components.",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 11
          },
          {
            "id": 3,
            "title": "Implement Room ID Display",
            "description": "Display room IDs on or near each bounding box",
            "details": "Add text labels showing room IDs (e.g., \"room_001\") on or near each detected room's bounding box.",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 11
          },
          {
            "id": 4,
            "title": "Add Click Interaction Handlers",
            "description": "Implement click handlers for room selection",
            "details": "Add event handlers to detect clicks on bounding boxes and provide visual feedback (e.g., highlighting) when a room is selected.",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 11
          },
          {
            "id": 5,
            "title": "Integrate API Calls with Error Handling",
            "description": "Connect frontend to backend API with proper error handling",
            "details": "Implement API calls to the backend endpoint (from task 9) to fetch room detection results, with proper error handling for network issues and invalid responses.",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 11
          }
        ]
      },
      {
        "id": 12,
        "title": "Implement Observability Features",
        "description": "Add UI elements to display processing metrics such as detection time and confidence score.",
        "status": "done",
        "dependencies": [
          11
        ],
        "priority": "medium",
        "details": "Enhance the UI to show metrics like rooms detected, processing time, and confidence score using Material UI components. Ensure integration with React components for real-time updates.",
        "testStrategy": "Verify that metrics are accurately displayed and updated in real-time during processing. Implement component tests using Jest and React Testing Library to cover metrics display rendering, real-time updates, Material UI component integration, and accurate calculation and display of metrics.",
        "subtasks": [
          {
            "id": 1,
            "title": "Create Jest and React Testing Library tests",
            "description": "Develop component tests for metrics display rendering, real-time updates, and Material UI integration.",
            "dependencies": [],
            "details": "Include at least 3-5 test cases to ensure good coverage of the observability features.",
            "status": "done",
            "testStrategy": "Ensure tests cover rendering, updates, and integration aspects."
          },
          {
            "id": 2,
            "title": "Create Metrics Display Component",
            "description": "Build Material UI component to display metrics",
            "details": "Create a React component using Material UI (e.g., Card, Typography) to display metrics like rooms detected count, processing time, and confidence score.",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 12
          },
          {
            "id": 3,
            "title": "Implement Processing Time Calculation",
            "description": "Calculate and display processing time",
            "details": "Track the time from when room detection starts until results are received, and display it in a user-friendly format (e.g., \"2.34 seconds\").",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 12
          },
          {
            "id": 4,
            "title": "Implement Confidence Score Calculation",
            "description": "Calculate confidence score for detections",
            "details": "Implement logic to calculate a confidence score (0.00-1.00) based on factors like cycle size, shape regularity, and detection quality.",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 12
          },
          {
            "id": 5,
            "title": "Add Real-Time Updates",
            "description": "Update metrics in real-time during processing",
            "details": "Implement real-time updates to the metrics display as processing progresses, using React state management and potentially WebSocket or polling.",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 12
          }
        ]
      },
      {
        "id": 13,
        "title": "Implement Human-in-the-Loop UX",
        "description": "Allow users to interact with detected rooms, such as highlighting and renaming.",
        "status": "done",
        "dependencies": [
          11
        ],
        "priority": "medium",
        "details": "Add functionality for users to click on rooms to highlight them, rename, or remove incorrect detections. Implement React components for these interactions using Material UI.",
        "testStrategy": "Conduct usability testing to ensure interactions are intuitive and responsive. Additionally, implement component tests using Jest and React Testing Library to cover room highlighting on click, room renaming functionality, room removal functionality, user interaction handling, and Material UI component behavior. Include at least 5-7 component test cases with good coverage.",
        "subtasks": [
          {
            "id": 1,
            "title": "Test Room Highlighting",
            "description": "Create a test case for room highlighting on click using Jest and React Testing Library.",
            "dependencies": [],
            "details": "Ensure the room is highlighted correctly when clicked.",
            "status": "done",
            "testStrategy": "Verify the room's visual state changes upon interaction."
          },
          {
            "id": 2,
            "title": "Test Room Renaming",
            "description": "Create a test case for room renaming functionality using Jest and React Testing Library.",
            "dependencies": [],
            "details": "Ensure the room can be renamed and the change is reflected in the UI.",
            "status": "done",
            "testStrategy": "Check that the new name is displayed correctly after renaming."
          },
          {
            "id": 3,
            "title": "Test Room Removal",
            "description": "Create a test case for room removal functionality using Jest and React Testing Library.",
            "dependencies": [],
            "details": "Ensure the room can be removed and the UI updates accordingly.",
            "status": "done",
            "testStrategy": "Verify the room is no longer visible after removal."
          },
          {
            "id": 4,
            "title": "Test User Interaction Handling",
            "description": "Create a test case for handling user interactions using Jest and React Testing Library.",
            "dependencies": [],
            "details": "Ensure all user interactions are handled smoothly without errors.",
            "status": "done",
            "testStrategy": "Simulate user interactions and check for errors or unexpected behavior."
          },
          {
            "id": 5,
            "title": "Test Material UI Component Behavior",
            "description": "Create a test case for Material UI component behavior using Jest and React Testing Library.",
            "dependencies": [],
            "details": "Ensure Material UI components behave as expected during interactions.",
            "status": "done",
            "testStrategy": "Verify component behavior aligns with Material UI specifications."
          },
          {
            "id": 6,
            "title": "Implement Room Highlighting on Click",
            "description": "Add visual highlighting when a room is clicked",
            "details": "Implement click handlers that change the visual appearance (e.g., border color, background opacity) of a room's bounding box when clicked.",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 13
          },
          {
            "id": 7,
            "title": "Implement Room Renaming UI and Logic",
            "description": "Create UI for renaming rooms with Material UI components",
            "details": "Add a dialog or inline editing component using Material UI (e.g., TextField, Dialog) that allows users to rename detected rooms.",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 13
          },
          {
            "id": 8,
            "title": "Implement Room Removal Functionality",
            "description": "Add ability to remove incorrect room detections",
            "details": "Implement a delete/remove button or action that allows users to remove incorrectly detected rooms from the display and results.",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 13
          },
          {
            "id": 9,
            "title": "Add Material UI Components for Interactions",
            "description": "Integrate Material UI components for user interactions",
            "details": "Use Material UI components (e.g., IconButton, Menu, Dialog) to provide intuitive UI controls for room interactions (highlight, rename, remove).",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 13
          }
        ]
      },
      {
        "id": 14,
        "title": "Create Demo Video",
        "description": "Produce a video demonstrating the workflow and user experience.",
        "details": "Record a video showcasing the process from uploading a blueprint to interacting with detected rooms, highlighting key features and benefits.",
        "testStrategy": "Review video for clarity, completeness, and alignment with product goals.",
        "priority": "medium",
        "dependencies": [
          13
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 15,
        "title": "Prepare README Documentation",
        "description": "Write comprehensive documentation including value story, architecture, and roadmap.",
        "details": "Draft a README file that provides an overview of the project, setup instructions, and future development plans.",
        "testStrategy": "Ensure documentation is clear, accurate, and helpful for new developers.",
        "priority": "medium",
        "dependencies": [
          14
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 16,
        "title": "Conduct Performance Testing",
        "description": "Evaluate system performance against success criteria metrics.",
        "details": "Test the system with various blueprint sizes to measure detection accuracy, false positives, and processing latency.",
        "testStrategy": "Analyze results to confirm compliance with performance targets.",
        "priority": "medium",
        "dependencies": [
          11
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 17,
        "title": "Optimize Core Algorithm for Performance",
        "description": "The core algorithm currently exceeds all performance targets, making further optimization unnecessary for the MVP. Future scalability opportunities have been documented.",
        "status": "done",
        "dependencies": [
          16
        ],
        "priority": "medium",
        "details": "Optimization analysis completed. Current algorithm performance: Detection accuracy at 100%, false positives at 0%, and processing latency at 0.174s (172x faster than target). Primary bottleneck identified in split_lines_at_intersections() with O(n²) complexity. Documented future optimization opportunities include spatial indexing, early exit for simple floorplans, parallel processing, and caching.",
        "testStrategy": "No immediate re-testing required as all performance targets are exceeded. Future testing should focus on scalability improvements if optimization is pursued.",
        "subtasks": [
          {
            "id": 1,
            "title": "Document Optimization Opportunities",
            "description": "Compile and document potential optimization strategies for future scalability.",
            "dependencies": [],
            "details": "Include spatial indexing, early exit strategies, parallel processing, and caching.",
            "status": "done",
            "testStrategy": null
          }
        ]
      },
      {
        "id": 18,
        "title": "Prepare for Phase 2 Transition",
        "description": "Plan for the transition to AWS infrastructure post-MVP.",
        "details": "Outline steps for migrating to AWS, including setting up S3, API Gateway, Lambda, and other services.",
        "testStrategy": "Develop a detailed roadmap for Phase 2 implementation, ensuring alignment with MVP learnings.",
        "priority": "medium",
        "dependencies": [
          17
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 19,
        "title": "Create React UI Component for Wall Adjacency Graph Visualization",
        "description": "Develop a React component using Material UI to visualize the wall adjacency graph and highlight detected cycles.",
        "status": "done",
        "dependencies": [
          4,
          5,
          10
        ],
        "priority": "medium",
        "details": "Set up a new React component within the existing project structure. Use Material UI for styling and layout. Implement a canvas or SVG element to render the graph nodes and edges. Integrate with the backend to fetch graph data, including nodes, edges, and detected cycles. Highlight cycles using distinct colors or styles for easy identification. Ensure the component is responsive and can handle dynamic data updates. Provide controls for zooming and panning to navigate large graphs.",
        "testStrategy": "Test the component by integrating it with the backend endpoints from tasks 4 and 5. Use sample data to verify that the graph is rendered correctly and cycles are highlighted. Perform manual testing to ensure the UI is responsive and interactive. Validate that the component updates correctly when new data is received. Additionally, implement automated tests using Jest and React Testing Library to cover graph visualization rendering, cycle highlighting, node and edge display, zoom/pan controls, data updates, and Material UI integration. Include at least 5-7 component test cases with good coverage.",
        "subtasks": [
          {
            "id": 1,
            "title": "Set Up React Component Structure",
            "description": "Create the initial structure for the React component using Material UI.",
            "dependencies": [],
            "details": "Initialize a new React component file within the existing project. Use Material UI components for basic layout.",
            "status": "done",
            "testStrategy": "Ensure the component renders without errors."
          },
          {
            "id": 2,
            "title": "Implement Node and Edge Rendering",
            "description": "Render graph nodes and edges using canvas or SVG.",
            "dependencies": [
              1
            ],
            "details": "Use a canvas or SVG element to draw nodes and edges. Ensure nodes are positioned correctly and edges connect nodes.",
            "status": "done",
            "testStrategy": "Verify nodes and edges are rendered correctly with sample data."
          },
          {
            "id": 3,
            "title": "Highlight Detected Cycles",
            "description": "Implement cycle highlighting using distinct colors or styles.",
            "dependencies": [
              2
            ],
            "details": "Identify cycles in the graph data and apply distinct colors or styles to highlight them.",
            "status": "done",
            "testStrategy": "Check that cycles are highlighted correctly with test data."
          },
          {
            "id": 4,
            "title": "Add Zoom and Pan Controls",
            "description": "Implement controls for zooming and panning the graph.",
            "dependencies": [
              2
            ],
            "details": "Add interactive controls to allow users to zoom in/out and pan across the graph visualization.",
            "status": "done",
            "testStrategy": "Test zoom and pan functionality for smooth interaction."
          },
          {
            "id": 5,
            "title": "Integrate with Backend API",
            "description": "Fetch graph data from the backend and update the component.",
            "dependencies": [
              1,
              2,
              3,
              4
            ],
            "details": "Connect to the backend API to retrieve nodes, edges, and cycle data. Update the component to reflect dynamic data changes.",
            "status": "done",
            "testStrategy": "Ensure data is fetched and rendered correctly by simulating API responses."
          }
        ]
      },
      {
        "id": 20,
        "title": "Implement PDF Vector Extraction (Phase 2A)",
        "description": "Enable automatic extraction of wall line segments from PDF blueprint files, eliminating the need for manual JSON input.",
        "status": "in-progress",
        "dependencies": [
          9
        ],
        "priority": "high",
        "details": "Parse PDF vector graphics to extract wall line segments. Implement PDF parsing using PyMuPDF or pdfplumber, coordinate transformation to normalize PDF coordinates to 0-1000 range, line filtering to identify wall-like elements (thickness, style, layer), segment conversion to wall segment format, and validation to ensure extracted segments form valid wall connections. Create new API endpoint POST /detect-rooms-from-pdf that accepts PDF files, uploads them to S3, calls AWS services in parallel, processes responses, and returns room detection results. This approach uses pre-built AWS services (Textract, Rekognition) combined with our proven algorithms, as documented in PRD Section 9.0.",
        "testStrategy": "Test with various PDF types: CAD-generated PDFs (vector-based), scanned PDFs (raster embedded in PDF), multi-page blueprints, different coordinate systems. Compare extracted segments with ground truth JSON. Validate room detection accuracy matches JSON input method. Target: ≥ 85% of walls correctly extracted, < 2% coordinate transformation error, < 10 seconds processing latency for typical PDF (1-5 pages), < 15% false positives.",
        "subtasks": [
          {
            "id": 1,
            "title": "Set Up PDF Parsing Library",
            "description": "Integrate PyMuPDF or pdfplumber for PDF parsing.",
            "dependencies": [],
            "details": "Install and configure PyMuPDF or pdfplumber to extract vector graphics from PDF files.\n<info added on 2025-11-09T01:49:18.347Z>\nCompleted PDF parsing library setup:\n\n1. Installed PyMuPDF (fitz): Added to requirements.txt and installed successfully.\n2. Created PDF parser module (backend/src/pdf_parser.py):\n   - PDFParser class with configurable minimum line thickness.\n   - extract_lines() method to extract vector paths from PDF pages.\n   - extract_all_lines() method for multi-page PDFs.\n   - get_pdf_info() method for PDF metadata.\n   - Proper handling of PyMuPDF's drawing format:\n     - Line commands (\"l\", x1, y1, x2, y2).\n     - Move commands (\"m\", x, y).\n     - Curve commands (\"c\", ...) approximated as lines.\n   - Filtering by line thickness.\n   - Color extraction (RGB values).\n3. Test verification: Module imports and instantiates correctly.\n\nNext steps: Ready to move to subtask 20.2 (Extract Vector Paths) to test with actual PDF samples.\n</info added on 2025-11-09T01:49:18.347Z>",
            "status": "done",
            "testStrategy": "Verify library setup by parsing sample PDFs and checking for successful extraction of vector data."
          },
          {
            "id": 2,
            "title": "Extract Vector Paths from PDFs",
            "description": "Implement extraction of vector paths from PDF files.",
            "dependencies": [
              1
            ],
            "details": "Develop functionality to extract vector paths representing wall line segments from PDFs.\n<info added on 2025-11-09T01:49:51.310Z>\n✅ Completed vector path extraction implementation:\n\n1. **Enhanced PDF extraction**:\n   - Improved `extract_lines()` to properly handle PyMuPDF's drawing format\n   - Support for line commands (\"l\"), move commands (\"m\"), and curve commands (\"c\")\n   - Proper handling of path items and coordinate extraction\n\n2. **Added conversion method**:\n   - `convert_to_wall_segments()` to convert PDFLineSegment to wall segment format\n   - Includes heuristic for load-bearing detection (thickness >= 3.0)\n   - Preserves PDF metadata (thickness, color, page_number)\n\n3. **Created comprehensive tests**:\n   - Unit tests for parser initialization and configuration\n   - Test for file not found error handling\n   - Test for PDFLineSegment creation\n   - All 5 tests passing ✅\n\n4. **Added test script**:\n   - `test_extraction_with_pdf()` function for testing with actual PDF files\n   - Command-line interface: `python -m src.pdf_parser <pdf_path>`\n   - Provides detailed extraction statistics and sample output\n\n**Status**: Vector path extraction is fully implemented and tested. Ready for coordinate transformation (subtask 20.3) once we have sample PDF files to test with.\n</info added on 2025-11-09T01:49:51.310Z>",
            "status": "done",
            "testStrategy": "Test extraction on various PDF samples to ensure paths are correctly identified."
          },
          {
            "id": 3,
            "title": "Coordinate Transformation Implementation",
            "description": "Normalize PDF coordinates to a 0-1000 range.",
            "dependencies": [
              2
            ],
            "details": "Transform extracted vector coordinates to a standardized 0-1000 range for consistency.\n<info added on 2025-11-09T01:52:00.640Z>\nCompleted coordinate transformation implementation:\n\n1. Implemented `transform_coordinates()` method:\n   - Finds bounding box of all extracted PDF lines\n   - Calculates scale factor to fit in 0-1000 range (preserving aspect ratio)\n   - Transforms all line coordinates using scale and offset\n   - Handles edge cases (empty list, degenerate cases, zero width/height)\n   - Clamps coordinates to target range as safety check\n\n2. Enhanced `convert_to_wall_segments()` method:\n   - Added `normalize` parameter to validate coordinates are in 0-1000 range\n   - Raises ValueError if coordinates are outside range when normalize=True\n   - Preserves PDF metadata (thickness, color, page_number)\n\n3. Created comprehensive tests (9 tests, all passing):\n   - Test simple line transformation\n   - Test aspect ratio preservation\n   - Test empty list handling\n   - Test degenerate cases (single point)\n   - Test large coordinates (2000x1500 → 0-1000)\n   - Test small coordinates (10x10 → 0-1000)\n   - Test conversion with normalized lines\n   - Test validation of invalid coordinates\n   - Test metadata preservation\n\n4. Updated test script:\n   - Added coordinate transformation step to `test_extraction_with_pdf()`\n   - Shows normalized coordinates in output\n\nStatus: Coordinate transformation is fully implemented and tested. Ready for line filtering (subtask 20.4).\n</info added on 2025-11-09T01:52:00.640Z>",
            "status": "done",
            "testStrategy": "Validate coordinate transformation by comparing transformed coordinates against expected values."
          },
          {
            "id": 4,
            "title": "Line Filtering and Segment Conversion",
            "description": "Filter lines and convert to wall segment format.",
            "dependencies": [
              3
            ],
            "details": "Filter extracted lines based on thickness, style, and layer, then convert to wall segment format.\n<info added on 2025-11-09T01:53:25.838Z>\nCompleted line filtering and segment conversion:\n\n1. Implemented `filter_wall_lines()` method:\n   - Filter by minimum/maximum thickness (walls typically thicker than annotations)\n   - Filter by minimum line length (walls typically longer than dimension lines)\n   - Filter by color (walls often black or specific colors)\n   - Uses Euclidean distance in RGB space for color matching\n   - Supports skipping color filtering by passing empty list\n   - Defaults to black color filtering if not specified\n\n2. Enhanced `convert_to_wall_segments()` method:\n   - Already implemented in previous subtask\n   - Validates normalized coordinates (0-1000 range)\n   - Converts to wall segment format compatible with existing parser\n   - Preserves PDF metadata (thickness, color, page_number)\n   - Includes heuristic for load-bearing detection (thickness >= 3.0)\n\n3. Created comprehensive tests (8 tests, all passing):\n   - Test filtering by thickness (min/max)\n   - Test filtering by line length\n   - Test filtering by color (with tolerance)\n   - Test combining all criteria\n   - Test empty list handling\n   - Test skipping color filtering (empty list)\n   - Test diagonal line length calculation\n\nStatus: Line filtering and segment conversion are fully implemented and tested. Ready for validation (subtask 20.6) or API endpoint (subtask 20.5).\n</info added on 2025-11-09T01:53:25.838Z>",
            "status": "done",
            "testStrategy": "Ensure filtering criteria correctly identify wall-like elements and conversion is accurate."
          },
          {
            "id": 5,
            "title": "Create API Endpoint for Room Detection",
            "description": "Develop POST /detect-rooms-from-pdf endpoint.",
            "dependencies": [
              4,
              11,
              12,
              13
            ],
            "details": "Implement API endpoint to accept PDFs, upload to S3, call AWS services in parallel, and return room detection results in the specified format.\n<info added on 2025-11-09T01:43:02.598Z>\nAccept PDF file uploads using multipart/form-data. Upload the PDF to S3 and call AWS services in parallel: Textract for OCR and Rekognition for object detection. Process the PDF using PyMuPDF/pdfplumber to apply our algorithm. Combine responses from AWS services with extracted wall segments and use the existing room detection algorithm. Return room detection results in PRD format. Implement error handling for AWS service failures and use our algorithms as a fallback if AWS services are unavailable.\n</info added on 2025-11-09T01:43:02.598Z>\n<info added on 2025-11-09T02:48:06.481Z>\nCompleted API endpoint implementation:\n\n1. Created `/detect-rooms-from-pdf` endpoint:\n   - Accepts PDF file upload via multipart/form-data\n   - Optional query parameters: `use_textract` and `use_rekognition` (default: false)\n   - Full processing pipeline:\n     - Upload PDF to S3\n     - (Optional) Call Textract and Rekognition in parallel\n     - Extract vector paths from PDF using PDFParser\n     - Transform coordinates to 0-1000 range\n     - Filter wall lines (thickness, length, color)\n     - Convert to wall segments\n     - Validate segments using SegmentValidator\n     - Detect rooms using existing algorithm\n     - Return PRD-compliant array format\n\n2. Integrated all components:\n   - S3Client for file upload\n   - TextractClient for optional OCR\n   - RekognitionClient for optional object detection\n   - PDFParser for vector extraction\n   - PDFValidator for segment validation\n   - Existing room detection algorithm\n\n3. Error handling:\n   - File type validation (PDF only)\n   - S3 upload error handling\n   - PDF parsing error handling\n   - Validation error handling\n   - Room detection error handling\n   - Proper cleanup of temporary files\n\n4. Dependencies:\n   - Added `python-multipart` for file uploads\n   - Added `python-dotenv` for environment variable loading\n\n5. Created manual testing guide:\n   - `PDF_API_MANUAL_TESTING.md` with detailed instructions\n   - curl examples\n   - Python requests examples\n   - Postman/Insomnia instructions\n   - Troubleshooting guide\n\nStatus: API endpoint is ready for manual testing. User can now test with a PDF file.\n</info added on 2025-11-09T02:48:06.481Z>",
            "status": "done",
            "testStrategy": "Test API with various PDFs to ensure correct room detection and response format."
          },
          {
            "id": 6,
            "title": "Validate Extracted Segments",
            "description": "Implement validation logic to ensure extracted segments form valid wall connections.",
            "dependencies": [
              4
            ],
            "details": "Validate that extracted segments form a connected graph, verify minimum segment length, and check for reasonable wall density. Ensure segments can be processed by the existing room detection algorithm.\n<info added on 2025-11-09T01:55:18.684Z>\nCompleted segment validation implementation:\n\n1. Created `SegmentValidator` class with configurable thresholds for segment count, length, wall density, and isolated ratio. Validates segments form a connected graph, checks minimum segment length, validates wall density, detects isolated segments, and checks cycle formation for room detection.\n\n2. Validation checks include ensuring a minimum of 3 segments, warning about short segments, checking wall density, verifying connectivity, and checking cycle formation.\n\n3. Statistics calculation includes segment count, total/average/min/max length, bounding box and area, and connectivity information.\n\n4. Created comprehensive tests (12 tests, all passing) covering various validation scenarios and modes.\n\n5. Added `validate_pdf_segments()` function for easy validation, supporting strict and non-strict modes.\n\nStatus: Validation is fully implemented and tested. Ready for API endpoint integration (subtask 20.5).\n</info added on 2025-11-09T01:55:18.684Z>",
            "status": "done",
            "testStrategy": null
          },
          {
            "id": 7,
            "title": "Create Frontend PDF Upload Component",
            "description": "Build React component for PDF file upload using Material UI.",
            "dependencies": [
              5
            ],
            "details": "Create a FileUpload component specifically for PDF files that integrates with the existing UI. Allow users to upload PDF files and display processing status. Use Material UI components for consistency.",
            "status": "pending",
            "testStrategy": null
          },
          {
            "id": 8,
            "title": "Integrate PDF Upload with Room Detection",
            "description": "Connect PDF upload component to the new API endpoint and display results.",
            "dependencies": [
              6
            ],
            "details": "Update App.tsx to handle PDF uploads, call the /detect-rooms-from-pdf endpoint, and display detected rooms in the existing visualization components. Show extraction metadata (segments_extracted, processing_time).",
            "status": "pending",
            "testStrategy": null
          },
          {
            "id": 9,
            "title": "Write Comprehensive Tests for PDF Extraction",
            "description": "Create unit and integration tests for PDF extraction functionality.",
            "dependencies": [
              5
            ],
            "details": "Test PDF parsing with various PDF types (CAD-generated, scanned, multi-page), coordinate transformation accuracy, line filtering effectiveness, and API endpoint integration. Compare results with ground truth JSON data.",
            "status": "pending",
            "testStrategy": null
          },
          {
            "id": 10,
            "title": "Integrate AWS Services",
            "description": "Implement integration with AWS Textract and Rekognition for enhanced detection.",
            "dependencies": [
              5
            ],
            "details": "Integrate Amazon Textract for OCR (room labels, dimensions) and Amazon Rekognition for object detection (doors, windows) as optional enhancements. Ensure parallel processing with our existing algorithms.",
            "status": "pending",
            "testStrategy": "Validate integration by comparing AWS service outputs with expected results and ensuring they enhance room detection accuracy."
          },
          {
            "id": 11,
            "title": "Set Up AWS S3 Integration",
            "description": "Configure Amazon S3 for PDF file storage (AWS requirement).",
            "details": "Set up S3 bucket, configure IAM roles and policies for S3 access, implement file upload functionality to S3, and handle file retrieval. S3 is required for AWS services (Textract, Rekognition) to access files.\n<info added on 2025-11-09T01:57:18.785Z>\nCompleted S3 integration code implementation:\n\n1. Installed boto3: Added boto3 and botocore to requirements.txt and installed successfully.\n\n2. Created S3Client class (backend/src/aws_s3.py):\n   - Initialize with bucket name, region, and credentials (from env vars or parameters).\n   - upload_file(): Upload files to S3 with automatic naming and folder support.\n   - get_file(): Download files from S3.\n   - delete_file(): Delete files from S3.\n   - get_file_url(): Generate presigned URLs for temporary access.\n   - file_exists(): Check if file exists.\n   - test_connection(): Test S3 connection and bucket access.\n\n3. Created comprehensive tests (14 tests, all passing):\n   - Test initialization with parameters and env vars.\n   - Test upload/download operations.\n   - Test error handling (file not found, access denied).\n   - Test file existence checks.\n   - Test presigned URL generation.\n   - Test connection validation.\n\n4. Created setup guides:\n   - AWS_S3_SETUP_GUIDE.md: Detailed step-by-step AWS Console instructions.\n   - AWS_CONSOLE_CHECKLIST.md: Quick checklist for AWS Console setup.\n   - backend/test_s3_connection.py: Test script to verify setup.\n\n5. Fixed deprecation warning: Updated datetime.utcnow() to datetime.now(timezone.utc).\n\nStatus: Code is ready. User needs to complete AWS Console setup (Steps 1-7 in AWS_S3_SETUP_GUIDE.md) and configure environment variables before testing.\n</info added on 2025-11-09T01:57:18.785Z>",
            "status": "in-progress",
            "dependencies": [],
            "parentTaskId": 20
          },
          {
            "id": 12,
            "title": "Integrate Amazon Textract for OCR",
            "description": "Integrate Amazon Textract to extract text labels and dimensions from PDFs.",
            "details": "Set up Textract client, implement document text detection, extract room labels and dimension numbers, parse Textract response to extract relevant text blocks, and prepare for Phase 2C (room label auto-population). This is optional but recommended for compliance and future Phase 2C functionality.",
            "status": "done",
            "dependencies": [
              11
            ],
            "parentTaskId": 20
          },
          {
            "id": 13,
            "title": "Integrate Amazon Rekognition for Object Detection",
            "description": "Integrate Amazon Rekognition to detect architectural elements (doors, windows).",
            "details": "Set up Rekognition client, implement label detection for architectural elements, filter results for doors, windows, and other relevant objects, and use results to enhance or filter wall detection. This is optional but recommended for compliance and enhancement.",
            "status": "done",
            "dependencies": [
              11
            ],
            "parentTaskId": 20
          }
        ]
      },
      {
        "id": 21,
        "title": "Implement Raster Image Processing (Phase 2B)",
        "description": "Enable automatic extraction of wall line segments from raster images (PNG, JPG, JPEG), supporting scanned blueprints and photographed floorplans using computer vision techniques. Integrate AWS services for enhanced processing.",
        "status": "pending",
        "dependencies": [
          20
        ],
        "priority": "high",
        "details": "Use OpenCV for image preprocessing, edge detection (Canny), and line detection (Hough transforms). Implement image preprocessing (grayscale conversion, noise reduction, contrast enhancement, rotation correction), edge detection with adaptive thresholds, line detection using Probabilistic Hough Line Transform, line filtering (by length, orientation, grouping parallel lines), segment conversion to wall segment format, and validation. Create new API endpoint POST /detect-rooms-from-image that accepts image files, uploads them to S3, calls AWS services (Textract for OCR, Rekognition for object detection) in parallel, processes responses, and returns room detection results. Handle variable image quality, noise, perspective distortion, different drawing styles, and text/annotations.",
        "testStrategy": "Test with various image types: high-resolution scanned blueprints, low-resolution photographs, different lighting conditions, various architectural styles, hand-drawn vs CAD-generated plans. Compare detected segments with ground truth JSON. Validate room detection accuracy matches JSON input method. Test parameter tuning for different image qualities. Target: ≥ 75% of walls correctly detected, < 25% false positive rate, < 15 seconds processing latency for typical image (2000x3000 pixels), works with images ≥ 150 DPI. Include tests for AWS service integration and response handling.",
        "subtasks": [
          {
            "id": 1,
            "title": "Set Up OpenCV Environment",
            "description": "Install and configure OpenCV for image processing tasks.",
            "dependencies": [],
            "details": "Ensure OpenCV is installed and configured in the development environment. Verify compatibility with existing libraries and tools.\n<info added on 2025-11-09T03:11:33.675Z>\nCompleted OpenCV environment setup:\n\n1. Added opencv-python==4.10.0.84 and numpy==1.26.4 to requirements.txt\n2. Installed OpenCV and NumPy successfully\n3. Verified installation:\n   - OpenCV version: 4.10.0.84\n   - NumPy version: 1.26.4\n   - Both libraries import correctly\n\nOpenCV is now ready for image processing tasks (preprocessing, edge detection, line detection).\n</info added on 2025-11-09T03:11:33.675Z>",
            "status": "done",
            "testStrategy": "Verify OpenCV installation by running a sample image processing script."
          },
          {
            "id": 2,
            "title": "Implement Image Preprocessing",
            "description": "Develop functions for grayscale conversion, noise reduction, and contrast enhancement.",
            "dependencies": [
              1
            ],
            "details": "Use OpenCV to convert images to grayscale, apply Gaussian blur for noise reduction, and enhance contrast using histogram equalization.\n<info added on 2025-11-09T03:12:22.706Z>\nCompleted image preprocessing implementation:\n\n1. Created ImagePreprocessor class (backend/src/image_preprocessor.py):\n   - PreprocessingConfig dataclass for configurable parameters\n   - to_grayscale(): Converts BGR/RGB/RGBA to grayscale\n   - reduce_noise(): Applies Gaussian blur for noise reduction\n   - enhance_contrast(): Supports both standard histogram equalization and CLAHE (adaptive)\n   - preprocess(): Full pipeline (grayscale → denoise → enhance)\n   - get_image_info(): Utility for image metadata\n\n2. Features:\n   - Handles both color and grayscale input images\n   - Configurable Gaussian blur kernel size and sigma\n   - Optional histogram equalization (standard or adaptive CLAHE)\n   - Automatic kernel size adjustment (ensures odd numbers)\n   - Support for BGR, RGB, BGRA, RGBA formats\n\n3. Created comprehensive tests (16 tests, all passing):\n   - Initialization with default and custom configs\n   - Grayscale conversion from BGR and already grayscale images\n   - Noise reduction with various kernel sizes\n   - Contrast enhancement (standard, adaptive, disabled)\n   - Full preprocessing pipeline\n   - Image info extraction\n   - Convenience function testing\n\n4. All tests passing ✅\n\nReady for next subtask: Edge and Line Detection (21.3).\n</info added on 2025-11-09T03:12:22.706Z>",
            "status": "done",
            "testStrategy": "Test preprocessing on various image types to ensure clarity and consistency."
          },
          {
            "id": 3,
            "title": "Develop Edge and Line Detection",
            "description": "Implement edge detection using Canny and line detection using Hough transforms.",
            "dependencies": [
              2
            ],
            "details": "Apply Canny edge detection with adaptive thresholds. Use Probabilistic Hough Line Transform for detecting lines.\n<info added on 2025-11-09T03:13:13.421Z>\nCompleted edge and line detection implementation:\n\n1. Created LineDetector class (backend/src/line_detector.py):\n   - EdgeDetectionConfig dataclass for Canny edge detection parameters\n   - LineDetectionConfig dataclass for Hough line transform parameters\n   - LineDetectionParams dataclass combining both configs\n   - detect_edges(): Applies Canny edge detection with configurable thresholds\n   - detect_lines(): Uses Probabilistic Hough Line Transform (HoughLinesP)\n   - detect_lines_from_image(): Complete pipeline (edges → lines)\n   - get_edge_statistics(): Edge pixel count, density, etc.\n   - get_line_statistics(): Line count, lengths, averages, etc.\n\n2. Features:\n   - Canny edge detection with configurable low/high thresholds\n   - Automatic aperture size validation (ensures 3, 5, or 7)\n   - Probabilistic Hough Line Transform for line detection\n   - Configurable parameters: rho, theta, threshold, min_line_length, max_line_gap\n   - Returns lines as (x1, y1, x2, y2) tuples\n   - Statistics utilities for debugging and analysis\n\n3. Created comprehensive tests (18 tests, all passing):\n   - Configuration dataclass tests\n   - Edge detection tests (with and without edges)\n   - Line detection tests (various scenarios)\n   - Statistics calculation tests\n   - Invalid input handling\n   - Convenience function tests\n\n4. All tests passing ✅\n\nReady for next subtask: Line Filtering and Segment Conversion (21.6).\n</info added on 2025-11-09T03:13:13.421Z>",
            "status": "in-progress",
            "testStrategy": "Validate edge and line detection accuracy against known patterns in test images."
          },
          {
            "id": 4,
            "title": "Create API Endpoint for Image Processing",
            "description": "Develop the POST /detect-rooms-from-image API endpoint.",
            "dependencies": [
              3,
              12,
              13,
              14
            ],
            "details": "Implement an API endpoint that accepts image files, uploads them to S3, calls AWS services in parallel, processes responses, and returns detected room segments.\n<info added on 2025-11-09T01:43:04.785Z>\nThe API endpoint should:\n\n1. Accept image file uploads using multipart/form-data.\n2. Upload images to S3.\n3. Call AWS Textract for OCR and Rekognition for object detection in parallel.\n4. Process images using OpenCV for line detection.\n5. Use Rekognition results to filter out non-wall elements.\n6. Combine AWS service responses with extracted wall segments.\n7. Apply the existing room detection algorithm.\n8. Return room detection results in PRD format.\n\nInclude error handling for AWS service failures and implement a fallback to our algorithms if AWS services are unavailable.\n</info added on 2025-11-09T01:43:04.785Z>\n<info added on 2025-11-09T03:18:27.673Z>\nCompleted API endpoint implementation for image processing:\n\n1. Created POST /detect-rooms-from-image endpoint:\n   - Accepts image file uploads (PNG, JPG, JPEG, BMP, TIFF)\n   - Validates file type and loads image using OpenCV\n   - Uploads image to S3 (folder: 'images/')\n   - Optional: Calls Textract and Rekognition in parallel\n   - Full processing pipeline:\n     * Image preprocessing (grayscale, noise reduction, contrast)\n     * Edge detection (Canny)\n     * Line detection (Hough transform)\n     * Line filtering (length, orientation, duplicates)\n     * Rekognition-based filtering (if enabled) - logs architectural elements\n     * Convert to wall segments with coordinate normalization\n     * Validate segments (using image_validator)\n     * Detect rooms using existing algorithm (tolerance=5.0)\n     * Return PRD-compliant format\n\n2. Features:\n   - Reuses existing AWS services (S3, Textract, Rekognition) from PDF endpoint\n   - Integrates all image processing modules (preprocessor, line_detector, line_filter)\n   - Uses image_validator for segment validation\n   - Handles errors gracefully with proper HTTP status codes\n   - Cleans up temporary files\n   - Returns array of rooms matching PRD format\n\n3. Error handling:\n   - File type validation\n   - Image loading validation\n   - No lines detected error\n   - No lines after filtering error\n   - Validation errors\n   - AWS service errors (logged, not fatal)\n\n4. Ready for testing ✅\n\nThe endpoint follows the same pattern as the PDF endpoint, ensuring consistency across the API.\n</info added on 2025-11-09T03:18:27.673Z>",
            "status": "done",
            "testStrategy": "Test API with various image inputs and verify response accuracy, including AWS service integration."
          },
          {
            "id": 5,
            "title": "Design Frontend UI for Image Upload",
            "description": "Create a user interface for uploading images and displaying results.",
            "dependencies": [
              4
            ],
            "details": "Develop a React component for image upload and display processing results using Material UI.",
            "status": "pending",
            "testStrategy": "Perform manual testing to ensure the UI is intuitive and responsive."
          },
          {
            "id": 6,
            "title": "Implement Line Filtering and Segment Conversion",
            "description": "Filter detected lines and convert to wall segment format.",
            "dependencies": [
              3
            ],
            "details": "Filter lines by length (walls typically longer than annotations), orientation (prefer horizontal/vertical but allow angles), group nearby parallel lines, and remove duplicates. Convert filtered lines to wall segment format with start/end coordinates.\n<info added on 2025-11-09T01:43:06.588Z>\nIncorporate AWS Rekognition object detection results to filter out lines corresponding to non-wall elements such as doors, windows, and stairs. Use these results to enhance the accuracy of wall line detection by excluding lines associated with identified non-wall objects.\n</info added on 2025-11-09T01:43:06.588Z>\n<info added on 2025-11-09T03:14:22.567Z>\nCompleted the implementation of line filtering and segment conversion:\n\n1. Developed the LineFilter class in backend/src/line_filter.py, featuring a LineFilterConfig dataclass for configurable filtering parameters.\n2. Implemented methods for filtering lines by length, orientation, grouping parallel lines, removing duplicates, and converting lines to wall segment format.\n3. Added support for coordinate normalization to a 0-1000 range based on image dimensions.\n4. Created comprehensive tests covering configuration, filtering, grouping, duplicate removal, and segment conversion, all of which are passing.\n5. AWS Rekognition integration for filtering non-wall elements will be addressed in Task 21.14.\n</info added on 2025-11-09T03:14:22.567Z>",
            "status": "done",
            "testStrategy": null
          },
          {
            "id": 7,
            "title": "Validate Extracted Segments from Images",
            "description": "Implement validation logic for image-extracted segments.",
            "dependencies": [
              4
            ],
            "details": "Ensure extracted segments form a connected graph, verify minimum segment count, and check for reasonable wall density. Validate that segments can be processed by the existing room detection algorithm.\n<info added on 2025-11-09T03:15:34.812Z>\nCompleted image segment validation implementation:\n\n1. Created image_validator.py module:\n   - Reuses existing SegmentValidator from pdf_validator.py (same validation logic)\n   - validate_image_segments() function with lenient defaults for image-extracted segments\n   - Uses same connectivity_tolerance=5.0 and max_isolated_ratio=0.9 as PDF validation\n   - Handles coordinate precision issues similar to PDF extraction\n\n2. Features:\n   - Same validation checks as PDF segments:\n     - Minimum segment count (at least 3)\n     - Minimum segment length\n     - Wall density check\n     - Connectivity check (with lenient tolerance)\n     - Cycle formation check\n   - Configurable tolerance and isolated ratio\n   - Returns validation results with errors, warnings, stats, and connectivity info\n\n3. Created comprehensive tests (8 tests, all passing):\n   - Connected segments validation\n   - Isolated segments validation (with lenient settings)\n   - Insufficient segments validation\n   - Strict mode validation\n   - Warnings generation\n   - Statistics extraction\n   - Connectivity information\n   - Custom tolerance settings\n\n4. All tests passing\n\nThe validation logic is identical for PDF and image-extracted segments since both go through the same normalization and processing pipeline. The lenient settings account for coordinate precision issues in both cases.\n</info added on 2025-11-09T03:15:34.812Z>",
            "status": "done",
            "testStrategy": null
          },
          {
            "id": 8,
            "title": "Create Frontend Image Upload Component",
            "description": "Build React component for image file upload (PNG, JPG, JPEG) using Material UI.",
            "dependencies": [
              4
            ],
            "details": "Create a FileUpload component specifically for image files that integrates with the existing UI. Allow users to upload image files and display processing status. Use Material UI components for consistency.",
            "status": "pending",
            "testStrategy": null
          },
          {
            "id": 9,
            "title": "Integrate Image Upload with Room Detection",
            "description": "Connect image upload component to the new API endpoint and display results.",
            "dependencies": [
              7
            ],
            "details": "Update App.tsx to handle image uploads, call the /detect-rooms-from-image endpoint, and display detected rooms in the existing visualization components. Show extraction metadata (segments_extracted, processing_time, image_dimensions).",
            "status": "pending",
            "testStrategy": null
          },
          {
            "id": 10,
            "title": "Implement Parameter Tuning Interface",
            "description": "Create UI controls for adjusting image processing parameters.",
            "dependencies": [
              7
            ],
            "details": "Add optional UI controls (sliders, inputs) for Canny thresholds, Hough parameters, and minimum line length. Allow users to fine-tune detection for different image qualities. Store user preferences.",
            "status": "pending",
            "testStrategy": null
          },
          {
            "id": 11,
            "title": "Write Comprehensive Tests for Image Processing",
            "description": "Create unit and integration tests for raster image processing functionality.",
            "dependencies": [
              4
            ],
            "details": "Test image preprocessing, edge detection, line detection with various image types (high-res scanned, low-res photos, different lighting, various styles). Compare results with ground truth JSON data. Test parameter tuning effectiveness. Include tests for AWS service integration.",
            "status": "pending",
            "testStrategy": null
          },
          {
            "id": 12,
            "title": "Set Up AWS S3 Integration",
            "description": "Configure Amazon S3 for image file storage (AWS requirement).",
            "details": "Set up S3 bucket, configure IAM roles and policies for S3 access, implement file upload functionality to S3, and handle file retrieval. S3 is required for AWS services (Textract, Rekognition) to access files.",
            "status": "pending",
            "dependencies": [],
            "parentTaskId": 21
          },
          {
            "id": 13,
            "title": "Integrate Amazon Textract for OCR",
            "description": "Integrate Amazon Textract to extract text labels and dimensions from images.",
            "details": "Set up Textract client, implement document text detection for images, extract room labels and dimension numbers, parse Textract response to extract relevant text blocks, and prepare for Phase 2C (room label auto-population). This is optional but recommended for compliance and future Phase 2C functionality.",
            "status": "pending",
            "dependencies": [
              12
            ],
            "parentTaskId": 21
          },
          {
            "id": 14,
            "title": "Integrate Amazon Rekognition for Object Detection",
            "description": "Integrate Amazon Rekognition to detect architectural elements and filter non-wall lines.",
            "details": "Set up Rekognition client, implement label detection for architectural elements (doors, windows, stairs), filter results for relevant objects, and use Rekognition results to filter out non-wall elements from line detection (e.g., dimensions, annotations). This helps improve line detection accuracy.",
            "status": "pending",
            "dependencies": [
              12
            ],
            "parentTaskId": 21
          }
        ]
      }
    ],
    "metadata": {
      "created": "2025-11-08T20:18:15.982Z",
      "updated": "2025-11-09T03:18:28.176Z",
      "description": "Tasks for master context"
    }
  }
}